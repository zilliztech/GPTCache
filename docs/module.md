# ðŸ¤— Modules

![GPTCache Struct](GPTCacheStructure.png)

## LLM Adapter

The LLM Adapter is designed to integrate different LLM models by unifying their APIs and request protocols. GPTCache offers a standardized interface for this purpose, with current support for ChatGPT integration.

  - [âœ“] Support OpenAI chatGPT API.
  - [ ] Support other LLMs, such as Hugging Face Hub, Bard, Anthropic, and self-hosted models like LLaMa.

**API Reference**: You can find more about APIs and examples [here](./references/adapter.html).

## Embedding Generator 

This **Embedding Generator** module is created to extract embeddings from requests for similarity search. GPTCache offers a generic interface that supports multiple embedding APIs, and presents a range of solutions to choose from. 

  - [âœ“] Disable embedding. This will turn GPTCache into a keyword-matching cache.
  - [âœ“] Support [OpenAI](https://platform.openai.com/docs/guides/embeddings) embedding API.
  - [âœ“] Support [ONNX](https://onnx.ai/) with the paraphrase-albert-small-v2-onnx model.
  - [âœ“] Support [Hugging Face](https://huggingface.co/) embedding API.
  - [âœ“] Support [Cohere](https://docs.cohere.ai/reference/embed) embedding API.
  - [âœ“] Support [SentenceTransformers](https://www.sbert.net) embedding API.
  - [âœ“] Support [fastText](https://fasttext.cc) embedding API.

**API Reference**: You can find more about APIs and examples [here](./references/embedding.html).

## Cache Storage

**Cache Storage** is where the response from LLMs, such as ChatGPT, is stored. Cached responses are retrieved to assist in evaluating similarity and are returned to the requester if there is a good semantic match. At present, GPTCache supports SQLite and offers a universally accessible interface for extension of this module.

  - [âœ“] Support [SQLite](https://sqlite.org/docs.html).
  - [âœ“] Support [PostgreSQL](https://www.postgresql.org/).
  - [âœ“] Support [MySQL](https://www.mysql.com/).
  - [âœ“] Support [MariaDB](https://mariadb.org/).
  - [âœ“] Support [SQL Server](https://www.microsoft.com/en-us/sql-server/).
  - [âœ“] Support [Oracle](https://www.oracle.com/).
  - [ ] Support [MongoDB](https://www.mongodb.com/).
  - [ ] Support [Redis](https://redis.io/).
  - [ ] Support [Minio](https://min.io/).
  - [ ] Support [Habse](https://hbase.apache.org//).
  - [ ] Support [ElasticSearch](https://www.elastic.co/)
  - [ ] Support [zincsearch](https://zinc.dev/)
  - [ ] Support other storages

**API Reference**: You can find more about APIs and examples [here](./references/cache.html).

## Vector Store

The **Vector Store** module helps find the K most similar requests from the input request's extracted embedding. The results can help assess similarity. GPTCache provides a user-friendly interface that supports various vector stores, including Milvus, Zilliz Cloud, and FAISS. More options will be available in the future.

  - [âœ“] Support [Milvus](https://milvus.io/).
  - [âœ“] Support [Zilliz Cloud](https://cloud.zilliz.com/).
  - [âœ“] Support [FAISS](https://faiss.ai/).
  - [ ] Support [Qdrant](https://qdrant.tech/)
  - [âœ“] Support [Chroma](https://www.trychroma.com/)
  - [ ] Support [PGVector](https://github.com/pgvector/pgvector)
  - [ ] Support other vector databases

## Cache Manager

The **Cache Manager** is responsible for controlling the operation of both the **Cache Storage** and **Vector Store**.
  - **Eviction Policy**:

  Currently, GPTCache makes decisions about evictions based solely on the number of lines. This approach can result in inaccurate resource evaluation and may cause out-of-memory (OOM) errors. We are actively investigating and developing a more sophisticated strategy.
    - [âœ“] LRU eviction policy
    - [âœ“] FIFO eviction policy
    - [ ] More complicated eviction policies

## Similarity Evaluator

This module collects data from both the **Cache Storage** and **Vector Store**, and uses various strategies to determine the similarity between the input request and the requests from the **Vector Store**. Based on this similarity, it determines whether a request matches the cache. GPTCache provides a standardized interface for integrating various strategies, along with a collection of implementations to use. The following similarity definitions are currently supported or will be supported in the future:

  - [âœ“] The distance we obtain from the **Vector Store**.
  - [âœ“] A model-based similarity determined using the albert_duplicate model from [Towhee](https://towhee.io/).
  - [âœ“] Exact matches between the input request and the requests obtained from the **Vector Store**.
  - [âœ“] Distance represented by applying linalg.norm from numpy to the embeddings.
  - [ ] BM25 and other similarity measurements
  - [ ] Support other models

**API Reference**: You can find more about APIs and examples [here](./references/similarity_evaluation.html).
 
  
#### Note: 
Not all combinations of different modules may be compatible with each other. For instance, if we disable the **Embedding Extractor**, the **Vector Store** may not function as intended. We are currently working on implementing a combination sanity check for **GPTCache**.